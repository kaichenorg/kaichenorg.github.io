<!DOCTYPE HTML>
<!--
	Halcyonic by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Home - Kai Chen's Homepage</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	</head>
	<body>
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header-wrapper">
					<header id="header" class="container">
						<div class="row">
							<div class="12u">

								<!-- Logo -->
									<h1><a href="index.html" id="logo">Kai Chen</a></h1>

								<!-- Nav -->
								<nav id="nav">
									<a href="index.html">Home</a>
									<a href="Research.html">Research</a>																				
									<a href="Publication.html">Publication</a>
									<a href="Tool.html">Tool</a>
									<a href="People.html">People</a>
									<a href="http://people.ucas.ac.cn/~kaichen">[中文]</a>
								</nav>

							</div>
						</div>
					</header>
					<div id="banner">
						<div class="container">
							<div class="row">
								<div class="8u 12u(mobile)">
									<!-- Banner Copy -->
										<p>Professor Kai Chen received his Ph.D. degree in the University of Chinese Academy of Science in 2010; 
											then he joined the Chinese Academy of Science in January 2010. He became the Associate Professor in 
											September 2012 and became the full Professor in October 2015.</p> 
										<p>His research interests include software and system security, artificial intelligence security, intelligent terminal security, privacy protection.</p>
										<p>Here are some of the latest interesting works:</p>
										
								</div>
								<div class="3u 12u(mobile)">
									<!-- Banner Image -->
										<a href="index.html" class="bordered-feature-image">
											<img src="images/KaiChen.jpg" alt="Kai Chen's Homepage" />
										</a>

								</div>
							</div>
						</div>
					</div>
				</div>

			<!-- Features -->
				<div id="features-wrapper">
					<div id="features">
						<div class="container">
							<div class="row">
								<!-- Feature #5 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/JenniferHo97/XAI-TREND-TEST" target="view_window" class="bordered-feature-image"><img src="images/papers/good-look-but.png" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing</h2>
									<p>We evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, 
										ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, 
										natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods.
										Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. 
										For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.
										 
										[<a href="https://github.com/JenniferHo97/XAI-TREND-TEST" target="view_window">CODE</a>]
									</p>
									
									<p>Our paper was accepted by the 2023 ACM SIGSAC Conference on Computer and Communications Security (CCS 2023).
										[<a href="https://dl.acm.org/doi/pdf/10.1145/3576915.3616605">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #4 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/zhuhong1996/AI-Guardian" target="view_window" class="bordered-feature-image"><img src="images/papers/AI-Guardian.jpg" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>AI-Guardian: Defeating Adversarial Attacks using Backdoors</h2>
									<p>We present AI-Guardian, a novel approach to defeating adversarial attacks that leverages intentionally embedded backdoors. We design a unique backdoor, called bijection backdoor, to change the behavior of the protected model, mitigating the impact of adversarial examples on the final outputs without affecting the model's performance on the original tasks. 
										We conduct extensive evaluation and experimental results show that AI-Guardian reduces the attack success rate from 97.3% to 3.2%, with only a 0.9% decline on the clean data accuracy. Furthermore, AI-Guardian introduces only 0.36% overhead to the model prediction time, almost negligible in most cases. 
										[<a href="https://github.com/zhuhong1996/AI-Guardian" target="view_window">CODE</a>]
									</p>
									
									<p>Our paper was accepted by the 44th IEEE Symposium on Security and Privacy (S&P 2023).
										[<a href="https://ieeexplore.ieee.org/document/10179473">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #4 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/PeiweiHu/AURC" target="view_window" class="bordered-feature-image"><img src="images/papers/AURC.jpg" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>AURC: Detecting Errors in Program Code and Documentation</h2>
									<p>We present AURC, a static framework for detecting code bugs of incorrect return checks and document defects. 
										We observe that three objects participate in the API invocation, the document, the caller (code that invokes API), 
										and the callee (the source code of API). Mutual corroboration of these three objects boosts the detection of code and documentation errors. 
										We evaluated AURC on ten popular codebases. AURC discovered 529 new bugs and 224 new document defects. 
										Maintainers acknowledge our findings and have accepted 222 code patches and 76 document patches. 
										[<a href="https://github.com/PeiweiHu/AURC" target="view_window">CODE</a>]
									</p>
									
									<p>Our paper was accepted by the 32nd USENIX Security Symposium (USENIX Security 2023).
										[<a href="https://www.usenix.org/system/files/sec23fall-prepub-437-hu-peiwei.pdf">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #3 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/waugustus/CarpetFuzz" class="bordered-feature-image"><img src="images/papers/carpetfuzz.png" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>CarpetFuzz: Automatic Program Option Constraint Extraction from	Documentation for Fuzzing</h2>
									<p>We proposed a novel technique for identifying and extracting constraints among program options from the documentation. To the best of our knowledge, this is the
										first study that tries to use NLP to automatically figure out the relationships among program options from the documentation.
										With the help of this technique, AFL finds 45.97% more paths that other fuzzers cannot discover. We implemented the	prototype tool, CarpetFuzz, and evaluated it on 20 popular
										real-world open-source programs. CarpetFuzz accurately extracted 88.85% of the relationships from their documents. Through fuzzing these programs with the valid option combinations
										obtained by CarpetFuzz, 57 unique crashes have been	found, 30 of which have been assigned with CVE IDs.[<a href="https://github.com/waugustus/CarpetFuzz">CODE</a>]</p>
									<p>Our paper was accepted by the 32nd USENIX Security Symposium (USENIX Security 2023).
										[<a href="https://www.usenix.org/system/files/sec23fall-prepub-467-wang-dawei.pdf">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #2 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/lvpeizhuo/Data-free_Backdoor" class="bordered-feature-image"><img src="images/papers/data-free.png" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>A Data-free Backdoor Injection Approach in Neural Networks</h2>

									<p>We propose a novel backdoor injection approach in a "data-free" manner. We design a novel loss function for fine-tuning the original model into the backdoored one using the substitute data that is irrelevant to the main task, 
										and optimize the fine-tuning to balance the backdoor injection and the performance on the main task. We conduct extensive experiments on various deep learning scenarios, 
										and the evaluation results demonstrate that our data-free backdoor injection approach can efficiently embed backdoors with a nearly 100% attack success rate. 
										[<a href="https://github.com/lvpeizhuo/Data-free_Backdoor">CODE</a>]
									
									<p>Our paper was accepted by the 32nd USENIX Security Symposium (USENIX Security 2023).
										[<a href="https://www.usenix.org/system/files/sec23fall-prepub-573-lv.pdf">PDF</a>]</p>
								</div>
							</div>
							<!-- <hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<div class="4u 12u(mobile)">
									<a href="clone/" class="bordered-feature-image"><img src="images/papers/pic02.jpg" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>Achieving Accuracy and Scalability Simultaneously in Detecting Application Clones on Android Market (TO BE UPDATED)</h2>

									<p>Besides traditional problems such as potential bugs, (smartphone) application clones on Android markets 
										bring new threats. Existing techniques achieve either accuracy or scalability, but not both. 
										To solve those problems, we use a geometry characteristic, called centroid, of dependency graphs to 
										measure the similarity between methods (code fragments) in two apps. 
										[<a href="https://www.youtube.com/watch?v=cetRMEV4f_8">demo</a>] </p>
									
									<p>Our paper was accepted by the 36th International Conference on Software Engineering (ICSE 2014).
										[<a href="paper/conference/androidclones-camera-ready-final-icse2014.pdf">PDF</a>]</p>
								</div>
							</div> -->
						</div>
					</div>
				</div>

			<!-- Content -->
			
			<div id="content-wrapper">
				<div id="content">
					<div class="container">
						<div class="row">
							<div class="12u">

								<!-- Main Content -->
									<section>
										<header>
											<h2>News</h2>
										</header>
										<p style="font-weight:bold;">
											1. <b>Recruiting</b>: Our lab is looking for Research Assistants (staff member), Post-Doctors, Ph.D. Students, MS Students, and Interns. If you are interested in our group, please contact us. 
										</p>
										<p>
											2. <b>Congratulation</b>: Kai Chen got the award "National Top-notch Youth Talents Program of China" (国家“万人计划”青年拔尖人才)
										</p>
										<p>
											3. <b>Congratulation</b>: Kai Chen got the award "Beijing Nova Program" (北京市“科技新星”)
										</p>
										<p>
											4. <b>Congratulation</b>: Our paper "CommanderSong: A Systematic Approach for Practical Adversarial Voice Recognition" was accepted by the 27th USENIX Security Symposium (USENIX Security, 2018). 
										</p>
										<p>
											5. <b>Congratulation</b>: Our paper "Mass Discovery of Android Traffic Imprints through Instantiated Partial Execution" was accepted by the 24th ACM Conference on Computer and Communications Security (CCS 2017).
										</p>
										<p>
											6. <b>Congratulation</b>: Our paper "SemFuzz: Semantics-based Automatic PoC Generation" was accepted by the 24th ACM Conference on Computer and Communications Security (CCS 2017).
										</p>
										<p>
											7. <b>Congratulation</b>: Our paper "Unleashing the Walking Dead: Understanding Cross-App Remote Infections on Mobile WebViews" was accepted by the 24th ACM Conference on Computer and Communications Security (CCS 2017).
										</p>
										<p>
											8. <strong>MassVet</strong>: a system for a large-scale analysis of potentially-harmful apps and mobile libraries.  Here is the <a href="http://sit.soic.indiana.edu/en/2015/09/06/massvet-usenix/">demo and media reports</a> of the system.
										</p>
										<p>
											9. <b>Congratulation</b>: Our paper "Following Devil's Footprints: Cross-Platform Analysis of Potentially Harmful Libraries on Android and iOS" was accepted by the 37th IEEE Symposium on Security and Privacy (Oakland 2016).
										</p>
										<p>
											10. <b>Congratulation</b>: Our paper "Dynamically Discovering Likely Memory Layout to Perform Accurate Fuzzing" was accepted by IEEE Transactions on Reliability 2016.
										</p>
										<p>
											11. <b>Congratulation</b>: Our paper "Finding Unknown Malice in 10 Seconds: Mass Vetting for New Threats at the Google-Play Scale" was accepted by USENIX Security 2015.
										</p>	
									</section>

							</div>
						</div>
					</div>
				</div>
			</div>

			<!-- Footer -->
			<div id="footer-wrapper">
				<footer id="footer" class="container">
					<div class="row">
						<div class="12u 12u(mobile)">

							<!-- Links -->
							<section>
								<header>
									<h2>Contact</h2>
								</header>								
								
								<div>
									<div class="row">
										<div class="2u 12u(mobile)">
											
										</div>
										<div class="2u 12u(mobile)">
											<ul class="link-list last-child">
												<li>Address:</li>
												<li>Email:</li>
												<li>Homepage:</li>
											</ul>
										</div>
										<div class="8u 12u(mobile)">
											<ul class="link-list last-child">
												<li>No. 19, Shucun Road, Haidian District, Beijing, China. Postcode: 100085</li>
												<li>chenkai@iie.ac.cn</li>
												<li><a href="http://www.kaichen.org/">http://www.kaichen.org/</a></li>
											</ul>
										</div>
										
									</div>
								</div>
							</section>

						</div>
						
					</div>
				</footer>
			</div>
			<!-- Copyright -->
			<div id="copyright">
				&copy; 2015-2023 Kai Chen. All rights reserved. | Design: <a href="http://html5up.net">HTML5 UP</a>
			</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/skel-viewport.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
