<!DOCTYPE HTML>
<!--
	Halcyonic by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Home - Kai Chen's Homepage</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	</head>
	<body>
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header-wrapper">
					<header id="header" class="container">
						<div class="row">
							<div class="12u">

								<!-- Logo -->
									<h1><a href="index.html" id="logo">Kai Chen</a></h1>

								<!-- Nav -->
								<nav id="nav">
									<a href="index.html">Home</a>
									<a href="Research.html">Research</a>																				
									<a href="Publication.html">Publication</a>
									<a href="Tool.html">Tool</a>
									<a href="People.html">People</a>
									<a href="http://people.ucas.ac.cn/~kaichen">[中文]</a>
								</nav>

							</div>
						</div>
					</header>
					<div id="banner">
						<div class="container">
							<div class="row">
								<div class="8u 12u(mobile)">
									<!-- Banner Copy -->
										<p>Professor Kai Chen received his Ph.D. degree in the University of Chinese Academy of Science in 2010; 
											then he joined the Chinese Academy of Science in January 2010. He became the Associate Professor in 
											September 2012 and became the full Professor in October 2015.</p> 
										<p>His research interests include software and system security, artificial intelligence security, intelligent terminal security, privacy protection.</p>
										<p>Here are some of the latest interesting works:</p>
										
								</div>
								<div class="3u 12u(mobile)">
									<!-- Banner Image -->
										<a href="index.html" class="bordered-feature-image">
											<img src="images/KaiChen.jpg" alt="Kai Chen's Homepage" />
										</a>

								</div>
							</div>
						</div>
					</div>
				</div>

			<!-- Features -->
				<div id="features-wrapper">
					<div id="features">
						<div class="container">
							<div class="row">
								<!-- Feature #5 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/JenniferHo97/XAI-TREND-TEST" target="view_window" class="bordered-feature-image"><img src="images/papers/good-look-but.png" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing</h2>
									<p>We evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, 
										ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, 
										natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods.
										Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. 
										For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.
										 
										[<a href="https://github.com/JenniferHo97/XAI-TREND-TEST" target="view_window">CODE</a>]
									</p>
									
									<p>Our paper was accepted by the 2023 ACM SIGSAC Conference on Computer and Communications Security (CCS 2023).
										[<a href="https://dl.acm.org/doi/pdf/10.1145/3576915.3616605">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #4 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/zhuhong1996/AI-Guardian" target="view_window" class="bordered-feature-image"><img src="images/papers/AI-Guardian.jpg" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>AI-Guardian: Defeating Adversarial Attacks using Backdoors</h2>
									<p>We present AI-Guardian, a novel approach to defeating adversarial attacks that leverages intentionally embedded backdoors. We design a unique backdoor, called bijection backdoor, to change the behavior of the protected model, mitigating the impact of adversarial examples on the final outputs without affecting the model's performance on the original tasks. 
										We conduct extensive evaluation and experimental results show that AI-Guardian reduces the attack success rate from 97.3% to 3.2%, with only a 0.9% decline on the clean data accuracy. Furthermore, AI-Guardian introduces only 0.36% overhead to the model prediction time, almost negligible in most cases. 
										[<a href="https://github.com/zhuhong1996/AI-Guardian" target="view_window">CODE</a>]
									</p>
									
									<p>Our paper was accepted by the 44th IEEE Symposium on Security and Privacy (S&P 2023).
										[<a href="https://ieeexplore.ieee.org/document/10179473">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #4 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/PeiweiHu/AURC" target="view_window" class="bordered-feature-image"><img src="images/papers/AURC.jpg" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>AURC: Detecting Errors in Program Code and Documentation</h2>
									<p>We present AURC, a static framework for detecting code bugs of incorrect return checks and document defects. 
										We observe that three objects participate in the API invocation, the document, the caller (code that invokes API), 
										and the callee (the source code of API). Mutual corroboration of these three objects boosts the detection of code and documentation errors. 
										We evaluated AURC on ten popular codebases. AURC discovered 529 new bugs and 224 new document defects. 
										Maintainers acknowledge our findings and have accepted 222 code patches and 76 document patches. 
										[<a href="https://github.com/PeiweiHu/AURC" target="view_window">CODE</a>]
									</p>
									
									<p>Our paper was accepted by the 32nd USENIX Security Symposium (USENIX Security 2023).
										[<a href="https://www.usenix.org/system/files/sec23fall-prepub-437-hu-peiwei.pdf">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #3 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/waugustus/CarpetFuzz" class="bordered-feature-image"><img src="images/papers/carpetfuzz.png" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>CarpetFuzz: Automatic Program Option Constraint Extraction from	Documentation for Fuzzing</h2>
									<p>We proposed a novel technique for identifying and extracting constraints among program options from the documentation. To the best of our knowledge, this is the
										first study that tries to use NLP to automatically figure out the relationships among program options from the documentation.
										With the help of this technique, AFL finds 45.97% more paths that other fuzzers cannot discover. We implemented the	prototype tool, CarpetFuzz, and evaluated it on 20 popular
										real-world open-source programs. CarpetFuzz accurately extracted 88.85% of the relationships from their documents. Through fuzzing these programs with the valid option combinations
										obtained by CarpetFuzz, 57 unique crashes have been	found, 30 of which have been assigned with CVE IDs.[<a href="https://github.com/waugustus/CarpetFuzz">CODE</a>]</p>
									<p>Our paper was accepted by the 32nd USENIX Security Symposium (USENIX Security 2023).
										[<a href="https://www.usenix.org/system/files/sec23fall-prepub-467-wang-dawei.pdf">PDF</a>]
									</p>
								</div>
							</div>
							<hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<!-- Feature #2 -->
								<div class="4u 12u(mobile)">
									<a href="https://github.com/lvpeizhuo/Data-free_Backdoor" class="bordered-feature-image"><img src="images/papers/data-free.png" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>A Data-free Backdoor Injection Approach in Neural Networks</h2>

									<p>We propose a novel backdoor injection approach in a "data-free" manner. We design a novel loss function for fine-tuning the original model into the backdoored one using the substitute data that is irrelevant to the main task, 
										and optimize the fine-tuning to balance the backdoor injection and the performance on the main task. We conduct extensive experiments on various deep learning scenarios, 
										and the evaluation results demonstrate that our data-free backdoor injection approach can efficiently embed backdoors with a nearly 100% attack success rate. 
										[<a href="https://github.com/lvpeizhuo/Data-free_Backdoor">CODE</a>]
									
									<p>Our paper was accepted by the 32nd USENIX Security Symposium (USENIX Security 2023).
										[<a href="https://www.usenix.org/system/files/sec23fall-prepub-573-lv.pdf">PDF</a>]</p>
								</div>
							</div>
							<!-- <hr style="opacity:0.3" width=100% color=#F5F5F5 SIZE=1/>
							<div class="row">
								<div class="4u 12u(mobile)">
									<a href="clone/" class="bordered-feature-image"><img src="images/papers/pic02.jpg" alt="" /></a>
								</div>
								<div class="8u 12u(mobile)">
									<h2>Achieving Accuracy and Scalability Simultaneously in Detecting Application Clones on Android Market (TO BE UPDATED)</h2>

									<p>Besides traditional problems such as potential bugs, (smartphone) application clones on Android markets 
										bring new threats. Existing techniques achieve either accuracy or scalability, but not both. 
										To solve those problems, we use a geometry characteristic, called centroid, of dependency graphs to 
										measure the similarity between methods (code fragments) in two apps. 
										[<a href="https://www.youtube.com/watch?v=cetRMEV4f_8">demo</a>] </p>
									
									<p>Our paper was accepted by the 36th International Conference on Software Engineering (ICSE 2014).
										[<a href="paper/conference/androidclones-camera-ready-final-icse2014.pdf">PDF</a>]</p>
								</div>
							</div> -->
						</div>
					</div>
				</div>


			<!-- Footer -->
			<div id="footer-wrapper">
				<footer id="footer" class="container">
					<div class="row">
						<div class="12u 12u(mobile)">

							<!-- Links -->
							<section>
								<header>
									<h2>Contact</h2>
								</header>								
								
								<div>
									<div class="row">
										<div class="2u 12u(mobile)">
											
										</div>
										<div class="2u 12u(mobile)">
											<ul class="link-list last-child">
												<li>Address:</li>
												<li>Email:</li>
												<li>Homepage:</li>
											</ul>
										</div>
										<div class="8u 12u(mobile)">
											<ul class="link-list last-child">
												<li>No. 19, Shucun Road, Haidian District, Beijing, China. Postcode: 100085</li>
												<li>chenkai@iie.ac.cn</li>
												<li><a href="http://www.kaichen.org/">http://www.kaichen.org/</a></li>
											</ul>
										</div>
										
									</div>
								</div>
							</section>

						</div>
						
					</div>
				</footer>
			</div>
			<!-- Copyright -->
			<div id="copyright">
				&copy; 2015-2023 Kai Chen. All rights reserved. | Design: <a href="http://html5up.net">HTML5 UP</a>
			</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/skel-viewport.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
